{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "formed-burton",
   "metadata": {},
   "source": [
    "![Inspire logo](../images/inspire_logo.png \"Inspire logo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-biotechnology",
   "metadata": {},
   "source": [
    "# Inspire | Summer 2021\n",
    "## CNN for handwritten number recognition\n",
    "\n",
    "Using this notebook, we will train a convolutional neural network (CNN) to recognise handwritten numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-lounge",
   "metadata": {},
   "source": [
    "# Get access to Python software packages\n",
    "These are software packages that have already been installed on the computer. Here we import the packages so that we can use their functions in our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "foreign-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "pd.set_option(\"max_columns\", 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-patrol",
   "metadata": {},
   "source": [
    "# Functions\n",
    "These functions are used later on in the code. You do not need to read or understand these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "minimal-andrews",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Load the dataset and split it into training, validation and test datasets.\"\"\"\n",
    "    validation_split = 0.1\n",
    "    (x_train_val, y_train_val), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        x_train_val, y_train_val, test_size=validation_split, \n",
    "        stratify=y_train_val, random_state=7)\n",
    "    return (x_train, y_train), (x_val, y_val), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "molecular-phone",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(x, y, i):\n",
    "    \"\"\"Show image i from a dataset of samples, x, and labels, y.\"\"\"\n",
    "    plt.subplots(figsize=(10, 10))\n",
    "    plt.imshow(x[i], cmap=plt.get_cmap(\"binary\"))\n",
    "    plt.title(f\"A handwritten number {y[i]}\")\n",
    "    plt.xticks(ticks=range(28))\n",
    "    plt.yticks(ticks=range(28));\n",
    "    \n",
    "    \n",
    "def show__multi_images(x, y, i):\n",
    "    \"\"\"Show 25 images from a dataset of samples, x, and labels, y.\n",
    "         Starting with image i.\"\"\"\n",
    "    n = 25\n",
    "    assert i+n <= x.shape[0], f\"i must be less than {x.shape[0]-n+1}.\"\n",
    "\n",
    "    print(f\"Data samples from {i} to {i+n-1}:\")\n",
    "    plt.subplots(figsize=(10, 10))\n",
    "    for j in range(n):\n",
    "        plt.subplot(5, 5, j+1)\n",
    "        plt.imshow(x[i+j], cmap=plt.get_cmap(\"binary\"))\n",
    "        plt.title(f\"Number {y[i+j]}\")\n",
    "        plt.xticks(ticks=[])\n",
    "        plt.yticks(ticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beautiful-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_and_label_data(x_train, y_train, x_val, y_val, x_test, y_test):\n",
    "    \"\"\"Return the data rescaled and with one-hot encoded labels. \"\"\"\n",
    "    # Rescale the matrices of numbers so that they are 0 to 1 instead of 0 to 255.\n",
    "    x_train = x_train.astype(\"float32\") / 255\n",
    "    x_val = x_val.astype(\"float32\") / 255\n",
    "    x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "    # Convert each label from a number from 0 to 9 to a 1x10 vector of 0s and 1s\n",
    "    num_classes = 10\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    return (x_train, y_train), (x_val, y_val), (x_test, y_test)\n",
    "\n",
    "\n",
    "def reshape_data_for_cnn(x_train, x_val, x_test):\n",
    "    \"\"\"Return the data reshaped for input to a CNN model. \"\"\"\n",
    "    # Reshape the datasets from (n, 28, 28) to (n, 28, 28, 1)\n",
    "    x_train = np.expand_dims(x_train, -1)\n",
    "    x_val = np.expand_dims(x_val, -1)\n",
    "    x_test = np.expand_dims(x_test, -1)\n",
    "    return x_train, x_val, x_test\n",
    "\n",
    "\n",
    "def prepare_data_for_cnn(x_train, y_train, x_val, y_val, x_test, y_test):\n",
    "    \"\"\"Return the data rescaled and reshaped ready for input to a CNN model. \"\"\"\n",
    "    # Rescale the matrices of numbers so that they are 0 to 1 instead of 0 to 255.\n",
    "    # Convert each label from a number from 0 to 9 to a 1x10 vector of 0s and 1s\n",
    "    (x_train, y_train), (x_val, y_val), (x_test, y_test) = scale_and_label_data(\n",
    "        x_train, y_train, x_val, y_val, x_test, y_test)\n",
    "\n",
    "    # Reshape the matrices from (n, 28, 28) to (n, 784)\n",
    "    x_train, x_val, x_test = reshape_data_for_cnn(x_train, x_val, x_test)\n",
    "    \n",
    "    return (x_train, y_train), (x_val, y_val), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "circular-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(hist):\n",
    "    \"\"\"Plot the metrics that were recorded in the log during model training \"\"\"\n",
    "    log = pd.DataFrame(hist.history) \n",
    "    ax = log.plot(title='Training')\n",
    "    ax.set_xlabel(\"Model training epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-designer",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "Load data samples, x, and their labels, y. The dataset is split into datasets that will be used for different stages of model development:\n",
    "+ training the model: x_train, y_train\n",
    "+ validation (testing the model during model development): x_val, y_val\n",
    "+ testing - a final test once model development is complete: x_test, y_test\n",
    "\n",
    "Each data sample is a different handwritten number. Each sample has a label, which tells us what that handwritten number is supposed to be. Each label will be an integer (whole number) between 0 and 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "arbitrary-advocate",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "interracial-hobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 54000 samples and 54000 labels in the training dataset.\n",
      "Each data sample in the training dataset is an image that is 28 pixels by 28 pixels.\n",
      "There are 6000 samples and labels in the validation dataset.\n",
      "There are 10000 samples and labels in the test dataset.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {x_train.shape[0]} samples and {y_train.shape[0]} labels in the training dataset.\")\n",
    "print(f\"Each data sample in the training dataset is an image that is {x_train.shape[1]} pixels by {x_train.shape[2]} pixels.\")\n",
    "print(f\"There are {x_val.shape[0]} samples and labels in the validation dataset.\")\n",
    "print(f\"There are {x_test.shape[0]} samples and labels in the test dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-saying",
   "metadata": {},
   "source": [
    "# Build a machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "legal-technician",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-lesbian",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "This changes the data to the size and scale that the model requires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "separate-recorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val), (x_test, y_test) = prepare_data_for_cnn(\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-story",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "previous-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "useful-profile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-gauge",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "spectacular-hormone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "422/422 [==============================] - 35s 82ms/step - loss: 0.7506 - accuracy: 0.7600 - val_loss: 0.1039 - val_accuracy: 0.9682\n",
      "Epoch 2/3\n",
      "422/422 [==============================] - 33s 79ms/step - loss: 0.1288 - accuracy: 0.9598 - val_loss: 0.0727 - val_accuracy: 0.9765\n",
      "Epoch 3/3\n",
      "422/422 [==============================] - 35s 82ms/step - loss: 0.0929 - accuracy: 0.9715 - val_loss: 0.0569 - val_accuracy: 0.9813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f056c3c9100>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 3\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, \n",
    "          epochs=epochs, validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-george",
   "metadata": {},
   "source": [
    "# Validation: How good is the trained model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "recovered-chancellor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing using the validation dataset:\n",
      "Loss: 0.05685357004404068\n",
      "Accuracy: 0.981333315372467\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_val, y_val, verbose=0)\n",
    "print(\"Testing using the validation dataset:\")\n",
    "print(\"Loss:\", score[0])\n",
    "print(\"Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-oakland",
   "metadata": {},
   "source": [
    "# Final test: How good is the final model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "inner-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_final_test = False  # INSPIRE: when model development is complete, change this to True\n",
    "\n",
    "if do_final_test:\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(\"Testing using the test dataset:\")\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-packaging",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
